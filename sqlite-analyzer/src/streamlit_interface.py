import streamlit as st
import sys
import os

# Se asume que este archivo (streamlit_interface.py) est√° en el mismo directorio (src)
# que langchain_chatbot.py. Si se ejecuta streamlit desde 'sqlite-analyzer/src/',
# langchain_chatbot ser√° directamente importable.
try:
    from langchain_chatbot import get_langchain_agent, logger
except ImportError as e:
    # Si la importaci√≥n directa falla, podr√≠a ser porque Streamlit se ejecuta desde un directorio superior.
    # Intentamos a√±adir 'src' al path si no est√° ya.
    current_dir = os.path.dirname(os.path.abspath(__file__))
    if current_dir not in sys.path:
        sys.path.insert(0, current_dir)
    
    # Tambi√©n, el directorio padre de 'src' (que ser√≠a 'sqlite-analyzer') podr√≠a necesitar estar en el path
    # para que las importaciones internas de langchain_chatbot como 'from src.module' funcionen
    # si langchain_chatbot.py usa 'from src. ...' y 'src' es un subdirectorio del path esperado.
    # langchain_chatbot.py ya maneja esto a√±adiendo su directorio padre ('sqlite-analyzer') al path.
    try:
        from langchain_chatbot import get_langchain_agent, logger
    except ImportError as e_inner:
        st.error(f"Error al importar m√≥dulos necesarios: {e_inner}. Aseg√∫rate de que la estructura de directorios es correcta. CWD: {os.getcwd()}, sys.path: {sys.path}")
        st.stop()

# --- Configuraci√≥n de la p√°gina de Streamlit ---
st.set_page_config(page_title="SinaSuite LangChain Chatbot", layout="wide")

st.title("‚öïÔ∏è SinaSuite LangChain Chatbot üí¨")
st.caption("Interact√∫a con el sistema de consulta m√©dica inteligente.")

# --- Disclaimer ---
st.warning("**AVISO:** Este es un sistema prototipo con fines de demostraci√≥n. Las respuestas pueden tardar en generarse y la informaci√≥n proporcionada no debe usarse para tomar decisiones m√©dicas reales.", icon="‚ö†Ô∏è")

# --- Barra lateral con informaci√≥n y ejemplos ---
st.sidebar.title("‚ÑπÔ∏è Informaci√≥n y Ejemplos")
st.sidebar.markdown("""
Este chatbot puede ayudarte con diversas tareas relacionadas con informaci√≥n m√©dica. Aqu√≠ tienes algunos ejemplos de lo que puedes preguntar:

**Saludos y General:**
- "Hola"
- "¬øQui√©n eres?"
- "¬øQu√© es SinaSuite?"
- "Ayuda"

**Consultas M√©dicas Generales (BioChat Engine):**
- "¬øCu√°les son los √∫ltimos avances en el tratamiento del infarto de miocardio?"
- "Expl√≠came la CRISPR-Cas9."
- "Busca informaci√≥n sobre la metformina y sus efectos secundarios."

**Consultas a la Base de Datos M√©dica (SQL Engine):**
*   "¬øCu√°l es el n√∫mero total de pacientes que hay en la base de datos?"
*   "¬øCu√°l es el nombre completo del paciente con ID 1001?"
*   "¬øCu√°l es la fecha de nacimiento del paciente con ID 1005?"
*   "¬øQu√© vacunas ha recibido el paciente con ID 1445 y en qu√© fechas?"
*   "¬øQu√© pacientes tienen alergias registradas y cu√°les son esas alergias?"
*   "¬øQu√© tipo de alergias hay? ¬øHay pacientes con alergia al polen?"
*   "¬øCu√°ntos pacientes han sido fusionados y en qu√© fechas se realizaron las fusiones?"
*   "¬øQu√© procedimientos m√©dicos est√°n autorizados y a qu√© tipo pertenecen?"
*   "¬øCu√°ntos diagn√≥sticos principales y secundarios se registraron en cada tipo de episodio durante el a√±o 2024?"
*   "¬øCu√°l es la prevalencia de alergias alimentarias frente a no alimentarias en hombres y mujeres, por rangos de edad?"
*   "¬øCu√°l es la distribuci√≥n de severidad de alergias por tipo de alergeno en pacientes activos?"
*   "¬øQu√© pacientes han sido fusionados como registros duplicados, cu√°ntas fusiones se realizaron en 2023 y en qu√© fechas espec√≠ficas ocurrieron?"
*   "De los 13074 procedimientos autorizados, ¬øcu√°ntos quedaron asociados a un episodio cerrado en ‚Äòrealizado‚Äô versus ‚Äòcancelado‚Äô o ‚Äòno realizado‚Äô, desglosado por tipo de procedimiento?"
*   "¬øCu√°les son los pacientes registrados con m√°s alergias y medicaciones?"
*   "Hazme un resumen de los datos cl√≠nicos del paciente MARIA DOLORES PRUEBAS101904 SINA101904."
*   "¬øHay alg√∫n paciente con pruebas de imagen?"
*   "¬øCu√°l es la edad del paciente 1010?"
*   "¬øQu√© pacientes hay hospitalizados?"
*   "¬øQu√© pruebas m√©dicas o informes tiene Mariana (ID 3163)? ¬øQu√© informaci√≥n hay sobre ella?"

**Exploraci√≥n del Esquema de la Base de Datos:**
- "Listar tablas del esquema"
- "Listar columnas de una tabla: PATI_PATIENTS"
- "Buscar en el esquema por palabra clave: diagn√≥stico"
- "Listar todas las columnas del esquema"

**Preguntas de seguimiento (usando contexto):**
- *(Despu√©s de preguntar por un paciente)* "¬øY cu√°les son sus medicamentos?"
- *(Despu√©s de listar tablas)* "Mu√©strame las columnas de la primera tabla."

**Nota:** El motor SQL es m√°s efectivo si las preguntas son claras y se refieren a conceptos presentes en la base de datos. Para investigaci√≥n general o temas m√©dicos amplios, el motor BioChat es m√°s adecuado.
""")

# --- Inicializaci√≥n del Agente y Memoria en st.session_state ---
if 'agent' not in st.session_state:
    try:
        with st.spinner("Inicializando agente... Por favor, espera."):
            st.session_state.agent = get_langchain_agent()
        if st.session_state.agent is None:
            st.error("No se pudo inicializar el agente LangChain. Revisa los logs del terminal para m√°s detalles.")
            logger.error("streamlit_interface.py: get_langchain_agent() devolvi√≥ None.")
            st.stop()
        logger.info("streamlit_interface.py: Agente LangChain inicializado y guardado en session_state.")
    except Exception as e:
        st.error(f"Excepci√≥n al inicializar el agente LangChain: {e}")
        logger.error(f"streamlit_interface.py: Excepci√≥n al inicializar el agente: {e}", exc_info=True)
        st.stop()

if 'memory' not in st.session_state:
    # Configurar la memoria aqu√≠ si es necesario o asegurarse de que el agente la maneja internamente.
    # Por ahora, asumimos que la memoria ConversationBufferMemory ya est√° en el agente.
    # Si necesitas pasarla expl√≠citamente o configurarla de forma diferente, este es el lugar.
    # Ejemplo: st.session_state.memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
    # Y luego pasarla al agente si su inicializaci√≥n lo permite.
    # Por simplicidad, y dado que el agente ya tiene memoria, no se inicializa expl√≠citamente aqu√≠ de nuevo.
    pass # La memoria ya est√° configurada dentro de get_langchain_agent

if 'history' not in st.session_state:
    st.session_state.history = [] # Formato: [{"role": "user"/"assistant", "content": "..."}]

# --- Mostrar historial del chat ---
for message in st.session_state.history:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- Entrada del usuario ---
user_input = st.chat_input("Escribe tu pregunta aqu√≠...")

if user_input:
    if st.session_state.agent is None:
        st.error("El agente no est√° inicializado. No se puede procesar la pregunta.")
    else:
        # A√±adir pregunta del usuario al historial y mostrarla
        st.session_state.history.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        # Procesar la pregunta con el agente y mostrar la respuesta en streaming
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            try:
                # Usar st.spinner para el mensaje "Pensando..."
                # El spinner se mostrar√° hasta que el primer chunk llegue o termine el stream.
                with st.spinner("Pensando... ü§î"):
                    # El agente ReAct espera un diccionario con la clave "input"
                    # y el m√©todo stream devuelve un generador de eventos/chunks.
                    # La memoria se gestiona internamente por el agente si se configur√≥ con ConversationBufferMemory.
                    response_stream = st.session_state.agent.stream({
                        "input": user_input,
                        # "chat_history": st.session_state.history # Descomentar si el agente espera el historial expl√≠citamente
                        })
                    
                    for chunk in response_stream:
                        # Los chunks pueden tener diferentes estructuras dependiendo del agente y LLM.
                        # Para un AgentExecutor, los tokens de salida suelen estar en chunk.get('output')
                        # o necesitar√°s inspeccionar el chunk para la clave correcta (ej. 'messages', 'content')
                        # Si el chunk es un string directamente (menos com√∫n para agentes complejos):
                        # if isinstance(chunk, str):
                        #    full_response += chunk
                        # elif isinstance(chunk, dict) and "output" in chunk:
                        #    full_response += chunk["output"]
                        
                        # Para AgentExecutor.stream, los eventos son diccionarios.
                        # El contenido de la respuesta final del LLM suele estar en eventos "on_chat_model_stream"
                        # bajo data -> chunk -> content
                        if "output" in chunk: # Para la salida final del agente ReAct
                            full_response += chunk["output"]
                            message_placeholder.markdown(full_response + "‚ñå") # A√±adir un cursor parpadeante
                        elif isinstance(chunk, dict) and chunk.get("event") == "on_chat_model_stream":
                            content = chunk.get("data", {}).get("chunk", {}).content
                            if content:
                                full_response += content
                                message_placeholder.markdown(full_response + "‚ñå")
                        # Puedes a√±adir logs aqu√≠ para inspeccionar la estructura de los chunks si es necesario
                        # logger.debug(f"Stream chunk: {chunk}")
                
                message_placeholder.markdown(full_response) # Respuesta final sin cursor
                logger.info(f"streamlit_interface.py: User: '{user_input}', Agent: '{full_response}'")

            except Exception as e:
                full_response = f"Error al procesar la pregunta: {e}"
                message_placeholder.error(full_response)
                logger.error(f"streamlit_interface.py: Error al invocar el agente para input '{user_input}': {e}", exc_info=True)

        # A√±adir respuesta del asistente al historial
        st.session_state.history.append({"role": "assistant", "content": full_response})

# --- Instrucciones para ejecutar ---
# st.sidebar.info("""
# **Para ejecutar esta aplicaci√≥n:**
# 1. Aseg√∫rate de tener Streamlit instalado (`pip install streamlit`).
# 2. Abre una terminal.
# 3. Navega al directorio `sqlite-analyzer/src/`.
#    (Ej: `cd c:\Users\cpascual\PycharmProjects\pythonProject\cursos_actividades\sina_mcp\sqlite-analyzer\src\`)
# 4. Ejecuta: `streamlit run streamlit_interface.py`
# """)
